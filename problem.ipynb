{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "executionInfo": {
     "elapsed": 1293,
     "status": "ok",
     "timestamp": 1711646935952,
     "user": {
      "displayName": "Nguyễn Đức Vũ",
      "userId": "07288779277842550568"
     },
     "user_tz": -420
    },
    "id": "48UH6zEyaSc8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import cosine\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1711646804012,
     "user": {
      "displayName": "Nguyễn Đức Vũ",
      "userId": "07288779277842550568"
     },
     "user_tz": -420
    },
    "id": "ZVdb62fRyhTn"
   },
   "outputs": [],
   "source": [
    "def load_vocab_dict(path: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "    \"\"\"\n",
    "    Reads a vocabulary list from a file and creates a dictionary mapping each word to its index.\n",
    "\n",
    "    Args:\n",
    "        path (str): The file path to the vocabulary list.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], Dict[str, int]]: A tuple containing the list of vocabulary words and a dictionary\n",
    "                                          mapping each word to its index.\n",
    "    \"\"\"\n",
    "    vocab = open(path).read().strip().split('\\n')\n",
    "    return vocab, {word: idx for idx, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1711646804013,
     "user": {
      "displayName": "Nguyễn Đức Vũ",
      "userId": "07288779277842550568"
     },
     "user_tz": -420
    },
    "id": "hkJ7fQifz532"
   },
   "outputs": [],
   "source": [
    "def read_corpus(path: str) -> List[str]:\n",
    "    \"\"\"Reads the corpus from a file, excluding the last empty entry if the file ends with a newline.\n",
    "\n",
    "    Args:\n",
    "        path (str): The file path to the corpus.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of strings, each representing a line from the file.\n",
    "    \"\"\"\n",
    "    return open(path).read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1711646804013,
     "user": {
      "displayName": "Nguyễn Đức Vũ",
      "userId": "07288779277842550568"
     },
     "user_tz": -420
    },
    "id": "_cgReXf9FIl2"
   },
   "outputs": [],
   "source": [
    "def counting(\n",
    "    corpus: List[str],\n",
    "    V: List[str],\n",
    "    V_C: List[str],\n",
    "    V_set: Dict[str, int],\n",
    "    V_C_set: Dict[str, int],\n",
    "    w: int,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates a co-occurrence (counting) matrix from the given corpus, considering specified vocabularies and a window size.\n",
    "\n",
    "    Args:\n",
    "        corpus (List[str]): The corpus as a list of sentences.\n",
    "        V (List[str]): The list of vocabulary words.\n",
    "        V_C (List[str]): The list of context vocabulary words.\n",
    "        V_set (Dict[str, int]): A dictionary mapping vocabulary words to their indices.\n",
    "        V_C_set (Dict[str, int]): A dictionary mapping context vocabulary words to their indices.\n",
    "        w (int): The window size for context.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A 2D NumPy array representing the co-occurrence matrix with dimensions (len(V), len(V_C)).\n",
    "    \"\"\"\n",
    "    # Initialize the matrix to hold word vectors\n",
    "    C = np.zeros((len(V), len(V_C)), dtype=float)\n",
    "\n",
    "    for line in tqdm(corpus):  # Iterate over each word in the original dataset\n",
    "        # Append start and end tokens to the sentence\n",
    "        words = [\"<s>\"] + line.split(\" \") + [\"</s>\"]\n",
    "        length = len(words)\n",
    "\n",
    "        for idx, word in enumerate(\n",
    "            words\n",
    "        ):  # Iterate over each word in the current sentence\n",
    "            # Skip '<s>' and '</s>', as they are not real words\n",
    "            from nltk.stem import WordNetLemmatizer \n",
    "            import nltk\n",
    "            nltk.download(\"wordnet\")\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            word = lemmatizer.lemmatize(word)\n",
    "            if idx > 0 and idx < length - 1 and word in V_set:\n",
    "                # Iterate over left and right context words within the window w\n",
    "                context_words = (\n",
    "                    words[max(idx - w, 0) : idx]\n",
    "                    + words[idx + 1 : min(idx + w + 1, length)]\n",
    "                )\n",
    "\n",
    "                # Constructs a co-occurrence matrix by iterating over context words\n",
    "                # within a specified range and increments counts in the matrix\n",
    "                # for each word-context pair found in a predefined vocabulary.\n",
    "                # It quantifies the relationship between words and their context in a corpus,\n",
    "                # essential for analyzing word associations.\n",
    "\n",
    "                ### BEGIN SOLUTION\n",
    "                for context_word in context_words:\n",
    "                    if context_word in V_C_set:\n",
    "                        C[V_set[word], V_C_set[context_word]] += 1\n",
    "                ### END SOLUTION\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "executionInfo": {
     "elapsed": 500,
     "status": "ok",
     "timestamp": 1711646943804,
     "user": {
      "displayName": "Nguyễn Đức Vũ",
      "userId": "07288779277842550568"
     },
     "user_tz": -420
    },
    "id": "_KAL4m9SDyKA"
   },
   "outputs": [],
   "source": [
    "def eval_word_similarity(C: np.ndarray, V_set: Dict[str, int], path: str) -> float:\n",
    "    \"\"\"\n",
    "    Evaluates word similarity by comparing a calculated similarity matrix against a gold standard dataset.\n",
    "\n",
    "    Args:\n",
    "        C (np.ndarray): A 2D NumPy array where rows represent words and columns represent their vector embeddings.\n",
    "        V_set (Dict[str, int]): A dictionary mapping words to their indices in the matrix C.\n",
    "        path (str): The file path to the gold standard dataset.\n",
    "\n",
    "    Returns:\n",
    "        float: The Spearman correlation coefficient between the gold standard similarity scores and the calculated scores.\n",
    "    \"\"\"\n",
    "    # Read the gold standard data, skipping the header and the last empty line if present\n",
    "    gold = [line.split(\"\\t\") for line in open(path).read().strip().split(\"\\n\")[1:]]\n",
    "\n",
    "    # Prepare gold scores and similarity scores\n",
    "    y = [float(line[2]) for line in gold]  # Extract gold standard similarity scores\n",
    "    x = [\n",
    "        (\n",
    "            1 - cosine(C[V_set[word_1], :], C[V_set[word_2], :])\n",
    "            if word_1 in V_set and word_2 in V_set\n",
    "            else 0\n",
    "        )\n",
    "        for word_1, word_2, _ in gold\n",
    "    ]\n",
    "\n",
    "    # Calculate and return Spearman correlation\n",
    "    return stats.spearmanr(x, y, axis=None).correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 114004,
     "status": "ok",
     "timestamp": 1711646918013,
     "user": {
      "displayName": "Nguyễn Đức Vũ",
      "userId": "07288779277842550568"
     },
     "user_tz": -420
    },
    "id": "tKH1dmT2D8V4",
    "outputId": "cbca5f46-8a0f-4da5-9a89-51835eb1dcf8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/997898 [00:00<?, ?it/s][nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "  0%|          | 1/997898 [00:23<6417:10:06, 23.15s/it][nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/variphx/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "  0%|          | 3/997898 [00:23<2139:53:16,  7.72s/it]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'benefits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[262], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m corpus \u001b[38;5;241m=\u001b[39m read_corpus(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/corpus.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Generate a co-occurrence (counting) matrix from the corpus using the main and context vocabularies.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# The window size 'w=3' indicates the context range around each target word to consider for co-occurrences.\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m C \u001b[38;5;241m=\u001b[39m \u001b[43mcounting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV_C\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV_C_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[260], line 55\u001b[0m, in \u001b[0;36mcounting\u001b[0;34m(corpus, V, V_C, V_set, V_C_set, w)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m context_word \u001b[38;5;129;01min\u001b[39;00m context_words:\n\u001b[1;32m     54\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m lemmatizer\u001b[38;5;241m.\u001b[39mlemmatize(context_word) \u001b[38;5;129;01min\u001b[39;00m V_C_set:\n\u001b[0;32m---> 55\u001b[0m                     C[V_set[word], \u001b[43mV_C_set\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcontext_word\u001b[49m\u001b[43m]\u001b[49m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     56\u001b[0m             \u001b[38;5;66;03m### END SOLUTION\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m C\n",
      "\u001b[0;31mKeyError\u001b[0m: 'benefits'"
     ]
    }
   ],
   "source": [
    "# Read the main vocabulary and its indices from a file,\n",
    "# creating a list of words (V) and a dictionary mapping words to indices (V_set).\n",
    "V, V_set = load_vocab_dict(\"./data/main_words.txt\")\n",
    "\n",
    "# Read the context vocabulary and its indices from a separate file,\n",
    "# creating a list of context words (V_C) and a dictionary mapping these words to indices (V_C_set).\n",
    "V_C, V_C_set = load_vocab_dict(\"./data/context_words.txt\")\n",
    "\n",
    "# Read the corpus from a text file, creating a list where each item represents a document or line in the corpus.\n",
    "corpus = read_corpus(\"./data/corpus.txt\")\n",
    "\n",
    "# Generate a co-occurrence (counting) matrix from the corpus using the main and context vocabularies.\n",
    "# The window size 'w=3' indicates the context range around each target word to consider for co-occurrences.\n",
    "C = counting(corpus, V, V_C, V_set, V_C_set, w=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 509,
     "status": "ok",
     "timestamp": 1711646948109,
     "user": {
      "displayName": "Nguyễn Đức Vũ",
      "userId": "07288779277842550568"
     },
     "user_tz": -420
    },
    "id": "3VvhpytXBs1A",
    "outputId": "24707dd3-b3ed-472d-8b03-52fee9edd664"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23223229343659896"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_word_similarity(C, V_set, \"./data/men.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1711646949884,
     "user": {
      "displayName": "Nguyễn Đức Vũ",
      "userId": "07288779277842550568"
     },
     "user_tz": -420
    },
    "id": "YNde13fFBxMz",
    "outputId": "f8b94b4c-a48d-4102-9f79-9d398fe9a9bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/scipy/spatial/distance.py:647: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / math.sqrt(uu * vv)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_word_similarity(C, V_set, \"./data/simlex-999.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22862,
     "status": "ok",
     "timestamp": 1711646974553,
     "user": {
      "displayName": "Nguyễn Đức Vũ",
      "userId": "07288779277842550568"
     },
     "user_tz": -420
    },
    "id": "vAn1zXmOE6zT"
   },
   "outputs": [],
   "source": [
    "def improve_C(C: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Improves the input co-occurrence matrix C using your specified technique.\n",
    "\n",
    "    Args:\n",
    "        C (np.ndarray): The co-occurrence matrix with shape (len(V), len(V_C)), where len(V) is the number of\n",
    "                        vocabulary words, and len(V_C) is the number of context words.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A matrix of shape (len(V), arbitrary_dimension).\n",
    "    \"\"\"\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    C_improved = C.copy()\n",
    "    M_i = C_improved.sum(axis=1)\n",
    "    M_j = C_improved.sum(axis=0)\n",
    "    \n",
    "    M_i_norm = np.linalg.norm(M_i)\n",
    "    M_j_norm = np.linalg.norm(M_j)\n",
    "\n",
    "    temp = np.outer(M_i, M_j) / (M_i_norm * M_j_norm)\n",
    "    temp[temp == 0] = 1e-16\n",
    "    temp *= C_improved.shape[0]\n",
    "\n",
    "    C_improved /= temp\n",
    "    C_improved[C_improved == 0] = 1e-10\n",
    "    return np.square(C_improved)\n",
    "    ### END SOLUTION\n",
    "\n",
    "\n",
    "C_improved = improve_C(C)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
